{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Scrape_Booklist:\n",
    "    def __init__(self, url, folder, payload=None):\n",
    "        self.payload = payload\n",
    "        self.url = url\n",
    "        self.folder = folder\n",
    "\n",
    "    def make_soup(self):\n",
    "        response = self.fetch_url_content()\n",
    "        soup = BeautifulSoup(response, 'html.parser')\n",
    "        return soup\n",
    "\n",
    "    def fetch_unless_present(self, url=None, extension=None):\n",
    "        if not url:\n",
    "            url = self.url\n",
    "        os.makedirs(self.folder, exist_ok=True)\n",
    "        if extension:\n",
    "            filename = '{}.{}'.format(os.path.split(url)[1], extension)\n",
    "        else:\n",
    "            filename = os.path.split(url)[1]\n",
    "        if filename not in os.listdir(self.folder):\n",
    "            binary = self.fetch_url_content(url)\n",
    "            self.write_binary_to_file(binary, filename)\n",
    "\n",
    "    def fetch_url_content(self, url=None):\n",
    "        if not url:\n",
    "            url = self.url\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36', }\n",
    "        response = requests.get(url, headers=headers, params=self.payload)\n",
    "        response.raise_for_status()\n",
    "        return response.content\n",
    "\n",
    "    def write_binary_to_file(self, binary, filename):\n",
    "        filepath = os.path.join(self.folder, filename)\n",
    "        with open(filepath, 'bw') as f:\n",
    "            f.write(binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_muse():\n",
    "    url = 'https://muse.jhu.edu/cgi-bin/book_title_list_html.cgi'\n",
    "    MuseScraping = Scrape_Booklist(url, 'muse_output')\n",
    "    partial_urls = [text\n",
    "                    for elem in MuseScraping.make_soup().find_all('a')\n",
    "                    if elem.text == 'Download'\n",
    "                    for attr, text in elem.attrs.items()\n",
    "                    if attr == 'href']\n",
    "    for partial_url in partial_urls:\n",
    "        full_url = 'https://muse.jhu.edu/{}'.format(partial_url)\n",
    "        MuseScraping.fetch_unless_present(url=full_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_wiley():\n",
    "    folder = 'wiley_output'\n",
    "    url = 'http://media.wiley.com/assets/2249/63/onlinebooks_list.xls'\n",
    "    WileyScraping = Scrape_Booklist(url, folder)\n",
    "    WileyScraping.fetch_unless_present()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_springer():\n",
    "    folder = 'springer_output'\n",
    "    url = 'http://ebookrecords.springer.com/marcdownload/file'\n",
    "\n",
    "    book_codes = [\"11641\", \"11640\", \"41168\", \"11642\", \"11643\", \"41169\", \"11644\",\n",
    "                  \"11645\", \"11645-LN\", \"11646\", \"41170\", \"41171\", \"40367\", \"11647\",\n",
    "                  \"41172\", \"11648\", \"41177\", \"41173\", \"11649\", \"11649-LN\", \"11650\",\n",
    "                  \"11651\", \"11651-LN\", \"41174\", \"12059\", \"41175\", \"41176\", ]\n",
    "    present_year = datetime.now().year\n",
    "    all_years = [str(i) for i in range(2005, present_year + 1)]\n",
    "    payload = {\"code\": book_codes,\n",
    "               \"year\": all_years,\n",
    "               \"format\": \"EBOOKLIST\",\n",
    "               \"grouping\": \"NONE\",\n",
    "               \"SBA\": \"true\",\n",
    "               \"date\": \"on\", }\n",
    "    SpringerScraping = Scrape_Booklist(url, folder, payload)\n",
    "    SpringerScraping.fetch_unless_present()\n",
    "    with zipfile.ZipFile(os.path.join(folder, 'file'), \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"springer_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_elsevier():\n",
    "    url = 'https://www.elsevier.com/solutions/sciencedirect/content/book-title-lists'\n",
    "    folder = 'elsevier_output'\n",
    "    ElsevierScraping = Scrape_Booklist(url, folder)\n",
    "    frontlist_urls = [text\n",
    "                      for elem in ElsevierScraping.make_soup().find_all('a')\n",
    "                      if 'Frontlist for' in elem.text\n",
    "                      for attr, text in elem.attrs.items()\n",
    "                      if attr == 'href']\n",
    "    backlist_urls = [text\n",
    "                     for elem in ElsevierScraping.make_soup().find_all('a')\n",
    "                     if 'Backlist for' in elem.text\n",
    "                     for attr, text in elem.attrs.items()\n",
    "                     if attr == 'href']\n",
    "    all_urls = frontlist_urls\n",
    "    all_urls.extend(backlist_urls)\n",
    "    for url in all_urls:\n",
    "        ElsevierScraping.fetch_unless_present(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_UPSO():\n",
    "    url = 'http://www.universitypressscholarship.com/fileasset/Title%20Lists/UPSO_Alltitles.xls'\n",
    "    folder = 'UPSO_output'\n",
    "    UPSOScraping = Scrape_Booklist(url, folder)\n",
    "    UPSOScraping.fetch_unless_present()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_JSTOR():\n",
    "    url = 'http://about.jstor.org/sites/default/files/misc/Books_at_JSTOR_Title_List.xls'\n",
    "    folder = 'JSTOR_output'\n",
    "    JSTORScraping = Scrape_Booklist(url, folder)\n",
    "    JSTORScraping.fetch_unless_present()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def scrape_cambridge():\n",
    "    url = 'https://www.cambridge.org/core/services/agents/price-list'\n",
    "    folder = 'cambridge_output'\n",
    "    CambridgeScraping = Scrape_Booklist(url, folder)\n",
    "    USD_urls = [text for elem in CambridgeScraping.make_soup().find_all('a')\n",
    "               if 'For USD click here' in elem.text\n",
    "               for attr, text in elem.attrs.items()\n",
    "               if attr == 'href']\n",
    "    for url in USD_urls:\n",
    "        CambridgeScraping.fetch_unless_present(url=url, extension='xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    answer = input(\"don't make them ban you -- You sure you want to scrape them again? (y/n):\")\n",
    "    if answer.lower() == 'y':\n",
    "        scrape_muse()\n",
    "        scrape_wiley()\n",
    "        scrape_springer()\n",
    "        scrape_elsevier()\n",
    "        scrape_UPSO()\n",
    "        scrape_JSTOR()\n",
    "        scrape_cambridge()\n",
    "    else:\n",
    "        quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
