{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publisher Spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import parse_publisher_sheets as Publishers\n",
    "importlib.reload(Publishers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_publ_dicts = Publishers.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publ_isbns_set = Publishers.make_set_all_isbns(all_publ_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bookstore csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import parse_bookstore_csv as Bookstore\n",
    "from collections import namedtuple\n",
    "\n",
    "ISBNregex = re.compile(r'(\\b\\d{13}\\b)|(\\b\\d{9}[\\d|X]\\b)')\n",
    "\n",
    "bookstore_csv_items = Bookstore.cleanup_original_text('/home/francis/Downloads/Summer_v2_bookstorelist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookstore_isbns_nts = dict()\n",
    "\n",
    "for num, row in enumerate(bookstore_csv_items):\n",
    "    if num == 0:\n",
    "        headers = row\n",
    "        BookstoreItemNT = namedtuple('BookstoreItemNT', [i.replace('/', '') for i in headers])\n",
    "        continue\n",
    "    isbn = row[7].replace('-', '')\n",
    "    bookstore_isbns_nts[isbn] = BookstoreItemNT(*row[:11])\n",
    "\n",
    "# bookstore_isbns = {row[7].replace('-', ''): row\n",
    "#                    for row in bookstore_csv_items\n",
    "#                    if ISBNregex.match(row[7].replace('-', ''))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symphony isbns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ISBNregex = re.compile(r'(\\b\\d{13}\\b)|(\\b\\d{9}[\\d|X]\\b)')\n",
    "\n",
    "def findISBNs(filepath, filename):\n",
    "    isbns = []\n",
    "    full_filepath = os.path.join(filepath, filename)\n",
    "    with open(full_filepath, \"r\", encoding=\"utf-8\", errors=\"surrogateescape\") as isbn_lines:\n",
    "        read_data = isbn_lines.readlines()\n",
    "    for line in read_data:\n",
    "        isbns.extend(ISBNregex.findall(line))\n",
    "    stripped = set()\n",
    "    stripped = {isbn.replace('-', '') for tuple_group in isbns for isbn in tuple_group if isbn}\n",
    "    return stripped\n",
    "\n",
    "Symphony_isbns = findISBNs('output', 'symphony.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worldcat expanding bookstore isbns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findEtextbooks as Combine\n",
    "\n",
    "importlib.reload(Combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sets_of_similar_isbns = list()\n",
    "for isbn in set(bookstore_isbns.keys()):\n",
    "    set_of_similar_isbns = Combine.find_similar_isbns(isbn)\n",
    "    sets_of_similar_isbns.append(set_of_similar_isbns)\n",
    "xCourseISBNs = Combine.flatten_set_of_sets(sets_of_similar_isbns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_similar_isbns(isbn):\n",
    "    for similar_set in sets_of_similar_isbns:\n",
    "        if isbn in similar_set:\n",
    "            return similar_set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import parse_course_catalog as CourseCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# course_file = 'course_listings/2017/Summer_2017/MUSIC3S17A.txt'\n",
    "# course_nts, season_dept = CourseCatalog.parse_course_listing_texts(course_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lookup_all_matching_courses(dept_coursenum, year, season):\n",
    "    yearpath = os.path.join('course_listings', year)\n",
    "    if not os.path.isdir(yearpath):\n",
    "        print('year must be among: {}'.format(', '.join(i for i in os.listdir(yearpath))))\n",
    "    seasonpath = os.path.join(yearpath, season)\n",
    "    if not os.path.isdir(seasonpath):\n",
    "        print('season must be among: {}'.format(', '.join(i for i in os.listdir(seasonpath))))\n",
    "    for root, dirs, files in os.walk(seasonpath):\n",
    "        for file in files:\n",
    "            sought_dept = dept_coursenum.split(' ')[0]\n",
    "            if sought_dept in file:\n",
    "                filepath = os.path.join(root, file)\n",
    "                course_nts, season_dept = CourseCatalog.parse_course_listings(filepath)\n",
    "                return [course_nt for course_nt in course_nts\n",
    "                        if course_nt.abbr_num.replace(' ', '') == dept_coursenum.replace(' ', '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "course_and_number = 'MUS 1751'\n",
    "year = '2017'\n",
    "season = 'Summer_2017'\n",
    "\n",
    "lookup_all_matching_courses(course_and_number, year, season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ebsco Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ebsco_discovery_functions as Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get alternate format isbns for an isbns from Ebsco Discovery\n",
    "import os\n",
    "import json\n",
    "\n",
    "def find_alt_isbns(relation_list):\n",
    "    alt_isbns = dict()\n",
    "    for relation in relation_list:\n",
    "        try:\n",
    "            identifiers = relation['BibEntity']['Identifiers']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        for identifier in identifiers:\n",
    "            if identifier and identifier['Type'] and 'isbn' in identifier['Type'].lower():\n",
    "                alt_isbns[identifier['Value']] = identifier['Type']\n",
    "    return alt_isbns\n",
    "\n",
    "def return_alternate_isbns(response_json):\n",
    "    alternate_isbn_type = dict()\n",
    "    records_list = response_json['SearchResult']['Data']['Records']\n",
    "    for record in records_list:\n",
    "        try:\n",
    "            record_relationships = record['RecordInfo']['BibRecord']['BibRelationships']['IsPartOfRelationships']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        alternate_isbn_type.update(find_alt_isbns(record_relationships))\n",
    "    return alternate_isbn_type\n",
    "\n",
    "def return_any_hits(response_json):\n",
    "    for database in response_json[\"SearchResult\"][\"Statistics\"][\"Databases\"]:\n",
    "        if database[\"Hits\"]:\n",
    "            return database\n",
    "\n",
    "for isbn, nt in bookstore_isbns_nts.items():\n",
    "    if not isbn or isbn.lower().strip() == \"none\":\n",
    "        continue\n",
    "    response = Discovery.main(isbn)\n",
    "    response_json = json.loads(response)\n",
    "    response_pretty = json.dumps(response_json, sort_keys=True, indent=2)\n",
    "    if return_any_hits(response_json):\n",
    "        target_dir = '/home/francis/Desktop/bookstore_discovery_hits/' \n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        with open('{}/{}.json'.format(target_dir, isbn),\n",
    "                  'w',\n",
    "                  encoding='utf-8') as f:\n",
    "            f.write(response_pretty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# finds if an isbn or it's cousin is in our holdings at Middleton or Hill, etc.\n",
    "\n",
    "all_matches_discovery = [os.path.join(root, file)\n",
    "                         for root, dirs, files in os.walk('/home/francis/Desktop/bookstore_discovery_hits/')\n",
    "                         for file in files]\n",
    "\n",
    "def is_file_in_holdings(discovery_json):\n",
    "    all_copy_locations = []\n",
    "    records_list = discovery_json['SearchResult']['Data']['Records']    \n",
    "    for record in records_list:\n",
    "        holdings_list = record.get('Holdings')\n",
    "        if not holdings_list:\n",
    "            continue\n",
    "        for holdings_info in holdings_list:\n",
    "            try:\n",
    "                copy_info_list = holdings_info['HoldingSimple']['CopyInformationList']\n",
    "            except KeyError:\n",
    "                continue\n",
    "            for copy_info in copy_info_list:\n",
    "                all_copy_locations.append(copy_info)\n",
    "    return all_copy_locations\n",
    "    \n",
    "for file in all_matches_discovery:\n",
    "    with open(file, 'r') as f:\n",
    "        parsed_json = json.load(f)\n",
    "    all_copy_locations = is_file_in_holdings(parsed_json)\n",
    "    if all_copy_locations:\n",
    "        filename = os.path.split(file)[1]\n",
    "        isbn = os.path.splitext(filename)[0]\n",
    "        print('{}: {}'.format(isbn, all_copy_locations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previously matched courses etextbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# identify prof/class in current courselist that used an etextbook previously\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def parse_previously_used_etextbooks(filename):\n",
    "    pandas_excel = pd.ExcelFile(filename)\n",
    "    cumulative_sheets = []\n",
    "    for sheetname in pandas_excel.sheet_names:\n",
    "        parsed_sheet = pd.read_excel(filename, sheetname=sheetname)\n",
    "        for index, row in parsed_sheet.iterrows():\n",
    "            row_dict = row.to_dict()\n",
    "            row_dict['Sheet'] = sheetname\n",
    "            cumulative_sheets.append(row_dict)\n",
    "    return cumulative_sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_this_seasons_course_catalog(current_year, current_season):\n",
    "    course_listings_path = os.path.abspath('course_listings')\n",
    "    yearpath = os.path.join(course_listings_path, current_year)\n",
    "    if not os.path.exists(yearpath):\n",
    "        print('year must be among:\\n\\n{}'.format('\\n'.join(i for i in os.listdir(course_listings_path))))\n",
    "        return False\n",
    "    seasonpath = os.path.join(yearpath, current_season)\n",
    "    if not os.path.isdir(seasonpath):\n",
    "        print('season must be among:\\n\\n{}'.format('\\n'.join(i for i in os.listdir(yearpath))))    \n",
    "    all_files = [os.path.join(root, file)\n",
    "                 for root, dirs, files in os.walk(seasonpath)\n",
    "                 for file in files]\n",
    "    return {os.path.splitext(os.path.split(filepath)[1])[0]:\n",
    "            CourseCatalog.parse_course_listings(filepath)[0]\n",
    "            for filepath in all_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumulative_etextbooks = '/home/francis/Desktop/lsu-git/etextbookSearch/source_material/Cumulative_Etextbooks.xlsx'\n",
    "parsed_previous_matches = parse_previously_used_etextbooks(cumulative_etextbooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_year, current_season = '2017', 'Summer_2017_Intersession'\n",
    "this_seasons_courses = parse_this_seasons_course_catalog(current_year, current_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def match_previous_to_current_courses(parsed_previous_matches, this_seasons_courses):\n",
    "    for course_filename, subcourses in this_seasons_courses.items():\n",
    "        for CourseItem in subcourses:\n",
    "            try:\n",
    "                course, number = [str(i) for i in CourseItem.abbr_num.split(' ') if i]\n",
    "                instructor = CourseItem.instructor\n",
    "            except ValueError:\n",
    "                for ok in ('SESSION', '', ):\n",
    "                    if not CourseItem.abbr_num or ok == CourseItem.abbr_num:\n",
    "                        break\n",
    "                    else:\n",
    "                        print('debug:  {} doesnt have right format course # or instructor'.format(CourseItem))\n",
    "                continue\n",
    "            for previous_match in parsed_previous_matches:\n",
    "#                 print(previous_match['Course'], '\\t\\t', course)\n",
    "#                 print(previous_match['Number'], '\\t\\t', number)\n",
    "                if previous_match['Course'].lower() in str(course).lower() and \\\n",
    "                    str(previous_match['Number']).lower() in str(number).lower() and \\\n",
    "                    str(previous_match['Instructor']).lower() in str(instructor).lower():\n",
    "                    print('Previous etextbook user:', previous_match, '\\n\\n', 'Possible current course match:', CourseItem, '\\n\\n\\n\\n')\n",
    "\n",
    "match_previous_to_current_courses(parsed_previous_matches, this_seasons_courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show all we know about an isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "isbn = '9780136017509'\n",
    "\n",
    "\n",
    "print('bookstore isbn:', isbn)\n",
    "print('similar isbns:', show_similar_isbns(isbn), '\\n')\n",
    "if show_similar_isbns(isbn):\n",
    "    for isbn in show_similar_isbns(isbn):\n",
    "        is_snippet_in_publisher_files_field(isbn, 'isbn')\n",
    "        print('\\n')\n",
    "        pub_item = publ_isbns_set.get(isbn)\n",
    "        if pub_item:\n",
    "            print(\"From Publisher websites:\", pub_item, '\\n')\n",
    "bookstore_item = bookstore_isbns.get(isbn)\n",
    "if bookstore_item:\n",
    "    bookstore_headers = ('Dept/Course', 'Section', 'empty1', 'Professor',\n",
    "   'Author', 'Title', 'empty2', 'ISBN', 'Publisher', 'RcCd', 'STS')\n",
    "    bookstore_item_dict = {k: v for k, v in zip(bookstore_headers, bookstore_item)}\n",
    "    print(\"From the B&N Bookstore csv:\", bookstore_item_dict, \"\\n\")\n",
    "    print('\\n')\n",
    "    print(\"From Course Catalog:\", lookup_course_catalog_item(bookstore_item_dict), '\\n')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_snippet_in_publisher_files_field(snippet, field):\n",
    "    for filename, sheets in all_publ_dicts.items():\n",
    "        for sheetname, textbooks in sheets.items():\n",
    "            for textbook, descriptor in textbooks.items():\n",
    "                for attribute, value in descriptor.items():\n",
    "                    if field.lower() in attribute.lower():\n",
    "                        if isinstance(value, str):\n",
    "                            if snippet.lower() in value.lower():\n",
    "                                print(descriptor)\n",
    "    print('no such \"{}\" in an Publishers spreadsheetfield with \"{}\" in the name'.format(snippet, field))\n",
    "\n",
    "is_snippet_in_publisher_files_field('9780136017509', 'isbn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiple_isbns():\n",
    "    pub_expanded_isbns = []\n",
    "    for filename, sheets in all_publ_dicts.items():\n",
    "        for sheetname, textbooks in sheets.items():\n",
    "            for textbook, descriptor in textbooks.items():\n",
    "                alternate_isbns = [i for i in descriptor if 'isbn' in i.lower()]\n",
    "                if len(alternate_isbns) > 1:\n",
    "                    pub_expanded_isbns.append(alternate_isbns)\n",
    "    return pub_expanded_isbns\n",
    "\n",
    "pub_expanded_isbns = multiple_isbns()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k, v in bookstore_items.items():\n",
    "    print(k, '\\t', v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in bookstore_isbns_nts.items():\n",
    "    print(k, \"\\t\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for isbn, nt in bookstore_isbns_nts.items():\n",
    "    syndetics_link = \"http://www.syndetics.com/index.aspx?isbn={}/LC.GIF&client=louislibnet&type=xw12&upc=&oclc=299047518&\".format(isbn)\n",
    "    requests.get"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
